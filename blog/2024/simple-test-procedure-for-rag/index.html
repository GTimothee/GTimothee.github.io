<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Test procedure and metrics for RAG in 5 minutes | Timothée Guédon </title> <meta name="author" content="Timothée Guédon"> <meta name="description" content="Simple test procedure and metrics for your RAG in 5 minutes"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, timothee, guedon, ai, deep-learning, data-science, generative-ai"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gtimothee.github.io/blog/2024/simple-test-procedure-for-rag/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Timothée</span> Guédon </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Test procedure and metrics for RAG in 5 minutes</h1> <p class="post-meta"> Created in October 04, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/rag"> <i class="fa-solid fa-hashtag fa-sm"></i> rag</a>   <a href="/blog/tag/evaluation"> <i class="fa-solid fa-hashtag fa-sm"></i> evaluation</a>   <a href="/blog/tag/procedure"> <i class="fa-solid fa-hashtag fa-sm"></i> procedure</a>   <a href="/blog/tag/metrics"> <i class="fa-solid fa-hashtag fa-sm"></i> metrics</a>   ·   <a href="/blog/category/rag"> <i class="fa-solid fa-tag fa-sm"></i> rag</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>In this blog post I show you how I build my simple evaluation procedure for a basic Q/A RAG system without use of external library or anything fancy. All you need is… an existing RAG system and to have access to an LLM. I also introduce two metrics I usually use to evaluate RAG systems, which are simple, quite robust, and easily interpretable in my opinion: completeness and conciseness.</p> </blockquote> <h2 id="motivation">Motivation</h2> <p><em>When you work in R&amp;D like me, you have limited time to build a PoC.</em> When working on RAG systems and AI agents in general, it is already a pain to select your tools, learn how to use them and build something robust. I will not explain you why you also need to evaluate the system, as it is pretty obvious.</p> <p><em>So you are faced with the following problem</em>: How do I focus on what I build, while also evaluating my RAG system fast, and in such a way that I can rapidly debug/improve the system. And the speed and interpretability criteria are key, in my opinion. In this blog post I show you how to build such system very fast, for rapid prototyping, without having to benchmark, test or dive into complicated frameworks with lots of metrics and settings. My solution is not fancy or complicated, but that is the whole point of it. If your PoC gets validated, you will have plenty of time to select a good RAG testing framework like RAGAS, spend time on elaborating advanced datasets, setup automated testing, etc. (I may dive into these advanced topics in future posts)</p> <h2 id="step-1--dataset-generation">Step 1 — Dataset generation</h2> <p>The dataset generation part is pretty simple. Go over each document chunk of your database and generate a question/answer pair for each chunk with the help of an LLM. Keep track of the chunk used for generation so that we can evaluate the RAG performance later. In other words, output a triple (question, answer, chunk) for each chunk.</p> <p>Here is a piece of code that does just that:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SYSTEM_PROMPT</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">You are an AI teacher, writing an exam out of course material.
Your task is to generate a (question, answer) pair from a given chunk from the course that is given to you.  
Return a JSON object with two keys:
- </span><span class="sh">'</span><span class="s">question</span><span class="sh">'</span><span class="s">: a question generated from the given chunk
- </span><span class="sh">'</span><span class="s">answer</span><span class="sh">'</span><span class="s">: the answer to the question
Just return the JSON, without any premamble or comment.

Chunk of the course material:
{chunk}
</span><span class="sh">"""</span>


<span class="k">class</span> <span class="nc">QAPair</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">question</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">question generated from the given chunk</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">answer</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">the answer to the question</span><span class="sh">"</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">isdir</span><span class="p">(</span>
        <span class="n">args</span><span class="p">.</span><span class="n">output_dir</span>
    <span class="p">),</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Output directory not found: </span><span class="si">{</span><span class="n">args</span><span class="p">.</span><span class="n">output_dir</span><span class="si">}</span><span class="sh">"</span>
    <span class="k">assert</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">isdir</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">chroma_dir</span><span class="p">),</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Chroma db not found: </span><span class="si">{</span><span class="n">args</span><span class="p">.</span><span class="n">chroma_dir</span><span class="si">}</span><span class="sh">"</span>

    <span class="nf">load_dotenv</span><span class="p">()</span>
    <span class="n">db</span> <span class="o">=</span> <span class="nf">get_db</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">chroma_dir</span><span class="p">)</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="c1"># your llm here
</span>    <span class="n">parser</span> <span class="o">=</span> <span class="nc">JsonOutputParser</span><span class="p">(</span><span class="n">pydantic_object</span><span class="o">=</span><span class="n">QAPair</span><span class="p">)</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="nc">PromptTemplate</span><span class="p">(</span>
        <span class="n">template</span><span class="o">=</span><span class="n">SYSTEM_PROMPT</span><span class="p">,</span>
        <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">chunk</span><span class="sh">"</span><span class="p">],</span>
        <span class="n">partial_variables</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">format_instructions</span><span class="sh">"</span><span class="p">:</span> <span class="n">parser</span><span class="p">.</span><span class="nf">get_format_instructions</span><span class="p">()},</span>
    <span class="p">)</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">llm</span> <span class="o">|</span> <span class="n">parser</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="nf">get</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">limit</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">n_chunks</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">limit</span>
        <span class="n">output_filename</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">qa_dataset_limit=</span><span class="si">{</span><span class="n">n_chunks</span><span class="si">}</span><span class="s">.csv</span><span class="sh">"</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_chunks</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">documents</span><span class="sh">"</span><span class="p">])</span>
        <span class="n">output_filename</span> <span class="o">=</span> <span class="sh">"</span><span class="s">qa_dataset.csv</span><span class="sh">"</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">:</span> <span class="p">[],</span> <span class="sh">"</span><span class="s">ground_truth_answer</span><span class="sh">"</span><span class="p">:</span> <span class="p">[],</span> <span class="sh">"</span><span class="s">chunk_id</span><span class="sh">"</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_chunks</span><span class="p">)):</span>
        <span class="n">chunk</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">documents</span><span class="sh">"</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">chain</span><span class="p">.</span><span class="nf">invoke</span><span class="p">({</span><span class="sh">"</span><span class="s">chunk</span><span class="sh">"</span><span class="p">:</span> <span class="n">chunk</span><span class="p">})</span>
        <span class="n">dataset</span><span class="p">[</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">])</span>
        <span class="n">dataset</span><span class="p">[</span><span class="sh">"</span><span class="s">ground_truth_answer</span><span class="sh">"</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">answer</span><span class="sh">"</span><span class="p">])</span>
        <span class="n">dataset</span><span class="p">[</span><span class="sh">"</span><span class="s">chunk_id</span><span class="sh">"</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">ids</span><span class="sh">"</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="nc">Path</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">output_filename</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p>Find the full code example <a href="https://github.com/GTimothee/RAG_experiments/blob/main/test_procedure_for_rag/generate_qa_pairs.py" rel="external nofollow noopener" target="_blank">here</a>.</p> <p>In the following of the post I only use a test set, but of course you can split it into a validation set and a test set, ensuring that the proportion of each source document is approximately the same in each set.</p> <h2 id="step-2--procedures-pseudo-code">Step 2 — Procedure’s pseudo code</h2> <p>Without further delay, let’s have a look at the full test procedure:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">each</span> <span class="n">document</span>
  <span class="k">for</span> <span class="n">each</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">document</span>
    <span class="c1"># 1- retrieve the answer from your system
</span>    <span class="n">run</span> <span class="n">your</span> <span class="n">RAG</span> <span class="n">system</span> <span class="n">on</span> <span class="n">the</span> <span class="n">question</span>
    <span class="n">gather</span> <span class="n">the</span> <span class="n">answer</span> <span class="ow">and</span> <span class="n">the</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">chunks</span> <span class="n">retrieved</span> <span class="ow">and</span> <span class="n">used</span> <span class="k">as</span> <span class="n">context</span>
    
    <span class="c1"># 2- evaluate
</span>    <span class="n">compute</span> <span class="n">your</span> <span class="n">performance</span> <span class="n">metrics</span> <span class="n">of</span> <span class="n">the</span> <span class="n">whole</span> <span class="n">system</span> <span class="n">by</span> <span class="n">comparing</span> <span class="n">the</span> <span class="n">answer</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">ground_truth</span>
    <span class="n">compute</span> <span class="n">your</span> <span class="n">rag</span> <span class="n">performance</span> <span class="n">by</span> <span class="n">saving</span> <span class="n">the</span> <span class="n">rank</span> <span class="n">of</span> <span class="n">the</span> <span class="n">target</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">contexts</span> <span class="nb">list</span> <span class="n">that</span> <span class="n">has</span> <span class="n">been</span> <span class="n">retrieved</span> <span class="n">by</span> <span class="n">your</span> <span class="n">system</span><span class="p">.</span> <span class="n">If</span> <span class="n">the</span> <span class="n">target</span> <span class="n">context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">there</span><span class="p">,</span> <span class="n">the</span> <span class="n">rank</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">something</span> <span class="n">equivalent</span><span class="p">.</span>
    <span class="n">Save</span> <span class="n">everything</span> <span class="k">as</span> <span class="n">a</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">csv</span> <span class="nb">file</span>
</code></pre></div></div> <p>That’s it. You get a csv file as output with all the data you need, you can now compute statistics like the completeness, conciseness and ranking distributions, the %match, %misses. A nice to have is to compute statistics per document (add a column to the csv file with the index or the name of the document).</p> <p>Here is an interpretation of the first part of the peudocode, to generate answers from the dataset:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rag_chain</span><span class="p">,</span> <span class="n">retriever</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="nf">get_rag_chain_eval</span><span class="p">(</span><span class="n">chroma_db_dirpath</span><span class="o">=</span><span class="n">path_to_your_db</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">dataset_filepath</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">answers</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span> <span class="sh">'</span><span class="s">ranks</span><span class="sh">'</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">itertuples</span><span class="p">(),</span> <span class="n">total</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sh">'</span><span class="s">Generating answers...</span><span class="sh">'</span><span class="p">):</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="n">retriever</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">question</span><span class="p">)</span>

    <span class="c1"># generate answer
</span>    <span class="n">output</span> <span class="o">=</span> <span class="n">rag_chain</span><span class="p">.</span><span class="nf">invoke</span><span class="p">({</span>
        <span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="n">question</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">context</span><span class="sh">"</span><span class="p">:</span> <span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">doc</span><span class="p">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">])</span>
    <span class="p">})</span>
    <span class="n">outputs</span><span class="p">[</span><span class="sh">'</span><span class="s">answers</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="c1"># compute rank of the target documents in the list of retrieved documents
</span>    <span class="n">target_chunk</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">chunk_id</span><span class="p">)[</span><span class="sh">'</span><span class="s">documents</span><span class="sh">'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">documents</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">chunk</span><span class="p">.</span><span class="n">page_content</span> <span class="o">==</span> <span class="n">target_chunk</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">outputs</span><span class="p">[</span><span class="sh">'</span><span class="s">ranks</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>

<span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">outputs</span><span class="p">).</span><span class="nf">to_csv</span><span class="p">(</span>
    <span class="nf">str</span><span class="p">(</span><span class="nc">Path</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="nc">Path</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">dataset_filepath</span><span class="p">).</span><span class="n">stem</span><span class="si">}</span><span class="sh">"</span> <span class="o">+</span> <span class="sh">"</span><span class="s">_answers.csv</span><span class="sh">"</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p>You can find the full code <a href="https://github.com/GTimothee/RAG_experiments/blob/main/test_procedure_for_rag/generate_answers.py" rel="external nofollow noopener" target="_blank">here</a></p> <p>Below is an interpretation of the second part of the pseudocode, to evaluate the answers. I use two metrics, completeness and conciseness to evaluate the RAG answers.</p> <p>Completeness evaluates whether or not the answer answers the question, while conciseness answers the question “how much of the answer is actually relevant”. If the completeness is low, then the system had trouble retrieving the relevant documents. If the conciseness is low, and the completeness is high, you are retrieving too much documents. So try to focus on improving the rank of the target document in the set of retrieved documents so that you can reduce the number of documents retrieved and reduce the noise. You could also add a reranker, which is probably a good idea in any RAG system.</p> <p>Additional comments about the evaluation prompt:</p> <ul> <li>I tried adding some other keys like ‘comments’ or ‘reasons’ to leverage the idea of chain of thoughts, but it did not provide any useful information</li> <li>I use floats here, but it may be that using integers from 1 to 10 instead would be more efficient or precise.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SYSTEM_PROMPT</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">You are a top-tier grading software belonging to a school.
Your task is to give a grade to evaluate the answer goodness to a given question, given the ground truth answer.

You will be given a piece of data containing: 
- a </span><span class="sh">'</span><span class="s">question</span><span class="sh">'</span><span class="s">
- an </span><span class="sh">'</span><span class="s">answer</span><span class="sh">'</span><span class="s">: the answer to the question from the student
- a </span><span class="sh">'</span><span class="s">ground truth answer</span><span class="sh">'</span><span class="s">: the expected answer to the question

Provide your answer as a JSON with two keys: 
- </span><span class="sh">'</span><span class="s">completeness</span><span class="sh">'</span><span class="s">: A float between 0 and 1. The percentage of the ground truth answer that is present in the student</span><span class="sh">'</span><span class="s">s answer. A score of 1 means that all the information in the </span><span class="sh">'</span><span class="s">ground truth answer</span><span class="sh">'</span><span class="s"> can be found in the </span><span class="sh">'</span><span class="s">answer</span><span class="sh">'</span><span class="s">. No matter if the answer contains more information than expected. A score of 0 means that no information present in the </span><span class="sh">'</span><span class="s">ground truth answer</span><span class="sh">'</span><span class="s"> can be found in the </span><span class="sh">'</span><span class="s">answer</span><span class="sh">'</span><span class="s">.
- </span><span class="sh">'</span><span class="s">conciseness</span><span class="sh">'</span><span class="s">: A float between 0 and 1. The percentage of the answer that is part of the ground truth. Conciseness measures how much of the answer is really useful.

Here is the data to evaluate: 
- </span><span class="sh">'</span><span class="s">question</span><span class="sh">'</span><span class="s">: {question}
- </span><span class="sh">'</span><span class="s">answer</span><span class="sh">'</span><span class="s">: {answer}
- </span><span class="sh">'</span><span class="s">ground truth answer</span><span class="sh">'</span><span class="s">: {ground_truth_answer}

Provide your answer as a JSON, with no additional text.
</span><span class="sh">"""</span>


<span class="k">class</span> <span class="nc">Evaluation</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">completeness</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">A float between 0 and 1. The percentage of the ground truth answer that is present in the student</span><span class="sh">'</span><span class="s">s answer. A score of 1 means that all the information in the </span><span class="sh">'</span><span class="s">ground truth answer</span><span class="sh">'</span><span class="s"> can be found in the </span><span class="sh">'</span><span class="s">answer</span><span class="sh">'</span><span class="s">. No matter if the answer contains more information than expected. A score of 0 means that no information present in the </span><span class="sh">'</span><span class="s">ground truth answer</span><span class="sh">'</span><span class="s"> can be found in the </span><span class="sh">'</span><span class="s">answer</span><span class="sh">'</span><span class="s">.</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">conciseness</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">A float between 0 and 1. The percentage of the answer that is part of the ground truth. Conciseness measures how much of the answer is really useful.</span><span class="sh">"</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>

    <span class="nf">load_dotenv</span><span class="p">()</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span>
        <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">dataset_filepath</span><span class="p">),</span>
        <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">answers_filepath</span><span class="p">)</span>
    <span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">llm</span> <span class="o">=</span> <span class="nc">OpenAI</span><span class="p">(</span>
        <span class="n">openai_api_base</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">OPENAI_BASE_URL</span><span class="sh">"</span><span class="p">),</span>
        <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">OPENAI_API_KEY</span><span class="sh">"</span><span class="p">),</span>
        <span class="n">model_name</span><span class="o">=</span><span class="sh">"</span><span class="s">Llama-3-70B-Instruct</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="nc">JsonOutputParser</span><span class="p">(</span><span class="n">pydantic_object</span><span class="o">=</span><span class="n">Evaluation</span><span class="p">)</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="nc">PromptTemplate</span><span class="p">(</span>
        <span class="n">template</span><span class="o">=</span><span class="n">SYSTEM_PROMPT</span><span class="p">,</span>
        <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">answer</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ground_truth_answer</span><span class="sh">"</span><span class="p">],</span>
        <span class="n">partial_variables</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">format_instructions</span><span class="sh">"</span><span class="p">:</span> <span class="n">parser</span><span class="p">.</span><span class="nf">get_format_instructions</span><span class="p">()},</span>
    <span class="p">)</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">llm</span> <span class="o">|</span> <span class="n">parser</span>

    <span class="n">conciseness</span><span class="p">,</span> <span class="n">completeness</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span>
    <span class="n">ranks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">itertuples</span><span class="p">(),</span> <span class="n">total</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sh">'</span><span class="s">Evaluating answers...</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">chain</span><span class="p">.</span><span class="nf">invoke</span><span class="p">({</span>
            <span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="n">question</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">answer</span><span class="sh">"</span><span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="n">answers</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">ground_truth_answer</span><span class="sh">"</span><span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="n">ground_truth_answer</span>
        <span class="p">})</span>
        <span class="n">completeness</span> <span class="o">+=</span> <span class="n">output</span><span class="p">[</span><span class="sh">'</span><span class="s">completeness</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">conciseness</span> <span class="o">+=</span> <span class="n">output</span><span class="p">[</span><span class="sh">'</span><span class="s">conciseness</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">ranks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">ranks</span><span class="p">)</span>
    
    <span class="n">mean_conciseness</span> <span class="o">=</span> <span class="n">conciseness</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="n">mean_completeness</span> <span class="o">=</span> <span class="n">completeness</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">({</span>
        <span class="sh">"</span><span class="s">mean_completeness</span><span class="sh">"</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">mean_completeness</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s"> %</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">mean_conciseness</span><span class="sh">"</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">mean_conciseness</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s"> %</span><span class="sh">"</span>
    <span class="p">})</span>

    <span class="nf">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">ranks</span><span class="p">).</span><span class="nf">value_counts</span><span class="p">())</span>
</code></pre></div></div> <p>Again, the full code is <a href="https://github.com/GTimothee/RAG_experiments/blob/main/test_procedure_for_rag/evaluate.py" rel="external nofollow noopener" target="_blank">here</a></p> <h2 id="disclaimer-it-is-for-qa-evaluation">Disclaimer: It is for Q/A evaluation</h2> <p>By Q/A evaluation I mean that each question of the test set is associated to (and can be answered with) one document chunk. Consequently, this evaluation procedure is for Q/A RAG only; Indeed, if you are looking for an answer for which you must gather data from multiple chunks, this procedure would not evaluate that. Still, I believe it is a good starting point when evaluating your RAG, as if you cannot reliably find one document chunk, how could you find multiple target document chunks? You could probably start with this procedure and then add another procedure for more complex use cases.</p> <h2 id="sources">Sources</h2> <p>To write the examples of this blog post, I relied on these two pages:</p> <ul> <li>https://huggingface.co/learn/cookbook/en/advanced_rag</li> <li>https://python.langchain.com/docs/tutorials/rag/#retrieval-and-generation-generate</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>Now you have a pretty good idea of how your RAG app performs. Now every time you want to add a document to the knowledge base, add it to the dataset and run the test. You will know how much the addition of the new chunks in the database interferes with the existing documents, and what is the performance of your RAG system on your new document.</p> <p>Medium link: https://medium.com/@timothee.guedon/simple-test-procedure-and-metrics-for-your-rag-in-5-minutes-a86b329a5f7a</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/patterns-to-problems-thoughts/">Stop Learning Patterns, Start Solving Problems - Lessons from Biology and Engineering</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/embedding-model-fine-tuning/">Embedding model fine-tuning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/homemade-keyword-retriever/">How to write your own keyword retriever in 5 minutes</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Timothée Guédon. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"My last projects",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-stop-learning-patterns-start-solving-problems-lessons-from-biology-and-engineering",title:"Stop Learning Patterns, Start Solving Problems - Lessons from Biology and Engineering",description:"This blog explores the shift from rigid categorization to creative problem-solving, drawing parallels between biology&#39;s evolution and modern engineering practices.",section:"Posts",handler:()=>{window.location.href="/blog/2025/patterns-to-problems-thoughts/"}},{id:"post-embedding-model-fine-tuning",title:"Embedding model fine-tuning",description:"Embedding model fine-tuning",section:"Posts",handler:()=>{window.location.href="/blog/2024/embedding-model-fine-tuning/"}},{id:"post-how-to-write-your-own-keyword-retriever-in-5-minutes",title:"How to write your own keyword retriever in 5 minutes",description:"Tutorial on how to write your own keyword retriever using the whoosh library",section:"Posts",handler:()=>{window.location.href="/blog/2024/homemade-keyword-retriever/"}},{id:"post-test-procedure-and-metrics-for-rag-in-5-minutes",title:"Test procedure and metrics for RAG in 5 minutes",description:"Simple test procedure and metrics for your RAG in 5 minutes",section:"Posts",handler:()=>{window.location.href="/blog/2024/simple-test-procedure-for-rag/"}},{id:"news-rag-agent-with-neo4j-tuto-update",title:"RAG agent with Neo4j tuto update",description:"",section:"News",handler:()=>{window.location.href="/news/2025-02-11-RAG-agent-with-Neo4j-tuto-update/"}},{id:"news-new-repo-on-rag-experiments",title:"New repo on RAG experiments",description:"",section:"News",handler:()=>{window.location.href="/news/2024-10-27-RAG-experiments-repo/"}},{id:"news-hello-world",title:"Hello world",description:"",section:"News",handler:()=>{window.location.href="/news/2024-06-12-Hello-world!/"}},{id:"projects-smolagent-custom-tools",title:"Smolagent custom tools",description:"Tools I built and shared with the community while building an agent with the smolagents library.",section:"Projects",handler:()=>{window.location.href="/projects/1_smolagents_tools_project/"}},{id:"projects-knowledge-graphs-project",title:"Knowledge graphs project",description:"Experimenting with knowledge graphs and RAG applications",section:"Projects",handler:()=>{window.location.href="/projects/2_knowledge_graphs_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%74%69%6D%6F%74%68%65%65.%67%75%65%64%6F%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>